{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_Convolutional_Neural_Networks",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOChJSNXtC9g",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLIxEDq6VhvZ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/logo.png\" width=150>\n",
        "\n",
        "In this lesson we will learn the basics of Convolutional Neural Networks (CNNs) applied to text for natural language processing (NLP) tasks. CNNs are traditionally used on images and there are plenty of [tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) that cover this. But we're going to focus on using CNN on text data which yields amazing results. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoMq0eFRvugb",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "The diagram below from this [paper](https://arxiv.org/abs/1510.03820) shows how 1D convolution is applied to the words in a sentence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziGJNhiQeiGN",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn_text.png\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWro5T5qTJJL",
        "colab_type": "text"
      },
      "source": [
        "* **Objective:**  Detect spatial substructure from input data.\n",
        "* **Advantages:** \n",
        "  * Small number of weights (shared)\n",
        "  * Parallelizable\n",
        "  * Detects spatial substrcutures (feature extractors)\n",
        "  * Interpretable via filters\n",
        "  * Used for in images/text/time-series etc.\n",
        "* **Disadvantages:**\n",
        "  * Many hyperparameters (kernel size, strides, etc.)\n",
        "  * Inputs have to be of same width (image dimensions, text length, etc.)\n",
        "* **Miscellaneous:** \n",
        "  * Lot's of deep CNN architectures constantly updated for SOTA performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nCsZGyWhI9f",
        "colab_type": "text"
      },
      "source": [
        "# Filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxpgRzIjiVHv",
        "colab_type": "text"
      },
      "source": [
        "At the core of CNNs are filters (weights, kernels, etc.) which convolve (slide) across our input to extract relevant features. The filters are initialized randomly but learn to pick up meaningful features from the input that aid in optimizing for the objective. We're going to teach CNNs in an unorthodox method where we entirely focus on applying it to 2D text data. Each input is composed of words and we will be representing each word as one-hot encoded vector which gives us our 2D input. The intuition here is that each filter represents a feature and we will use this filter on other inputs to capture the same feature. This is known as parameter sharing.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/conv.gif\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kTABJyYj91S",
        "colab_type": "code",
        "outputId": "6d74fb4f-1993-40c6-ebcd-3709d1b72adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Loading PyTorch library\n",
        "!pip3 install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz9D2rrdmSl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q1FiiIHXjI_",
        "colab_type": "text"
      },
      "source": [
        "Our inputs are a batch of 2D text data. Let's make an input with 64 samples, where each sample has 8 words and each word is represented by a array of 10 values (one hot encoded with vocab size of 10). This gives our inputs the size (64, 8, 10). The [PyTorch CNN modules](https://pytorch.org/docs/stable/nn.html#convolution-functions) prefer inputs to have the channel dim (one hot vector dim in our case) to be in the second position, so our inputs are of shape (64, 10, 8)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFfYwCcjZj79",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn_text1.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6G2nBvOxR-e",
        "colab_type": "code",
        "outputId": "954de2ec-30ac-4520-d139-8ed141c8934d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Assume all our inputs have the same # of words\n",
        "batch_size = 64\n",
        "sequence_size = 8 # words per input\n",
        "one_hot_size = 10 # vocab size (num_input_channels)\n",
        "x = torch.randn(batch_size, one_hot_size, sequence_size)\n",
        "print(\"Size: {}\".format(x.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([64, 10, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJmtay_UZohM",
        "colab_type": "text"
      },
      "source": [
        "We want to convolve on this input using filters. For simplicity we will use just 5 filters that is of size (1, 2) and has the same depth as the number of channels (one_hot_size). This gives our filter a shape of (5, 2, 10) but recall that PyTorch CNN modules prefer to have the channel dim (one hot vector dim in our case) to be in the second position so the filter is of shape (5, 10, 2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJF0l88qb-21",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn_text2.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMK2TzgDxR8B",
        "colab_type": "code",
        "outputId": "7c8afeee-89b4-4161-a299-c62752eb7376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Create filters for a conv layer\n",
        "out_channels = 5 # of filters\n",
        "kernel_size = 2 # filters size 2\n",
        "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=out_channels, kernel_size=kernel_size)\n",
        "print(\"Size: {}\".format(conv1.weight.shape))\n",
        "print(\"Filter size: {}\".format(conv1.kernel_size[0]))\n",
        "print(\"Padding: {}\".format(conv1.padding[0]))\n",
        "print(\"Stride: {}\".format(conv1.stride[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([5, 10, 2])\n",
            "Filter size: 2\n",
            "Padding: 0\n",
            "Stride: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAcYxhDIbeWE",
        "colab_type": "text"
      },
      "source": [
        "When we apply this filter on our inputs, we receive an output of shape (64, 5, 7). We get 64 for the batch size, 5 for the channel dim because we used 5 filters and 7 for the conv outputs because:\n",
        "\n",
        "$\\frac{W - F + 2P}{S} + 1 = \\frac{8 - 2 + 2(0)}{1} + 1 = 7$\n",
        "\n",
        "where:\n",
        "  * W: width of each input\n",
        "  * F: filter size\n",
        "  * P: padding\n",
        "  * S: stride"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c_KKtP4hrJx",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn_text3.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjxtrM89xR5a",
        "colab_type": "code",
        "outputId": "8cb370ac-ce4a-4348-9c76-6e4baa92399c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Convolve using filters\n",
        "conv_output = conv1(x)\n",
        "print(\"Size: {}\".format(conv_output.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([64, 5, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwTtF7bBuZvF",
        "colab_type": "text"
      },
      "source": [
        "# Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXBbKPs1ua9G",
        "colab_type": "text"
      },
      "source": [
        "The result of convolving filters on an input is a feature map. Due to the nature of convolution and overlaps, our feature map will have lots of redundant information. Pooling is a way to summarize a high-dimensional feature map into a lower dimensional one for simplified downstream computation. The pooling operation can be the max value, average, etc. in a certain receptive field.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/pool.jpeg\" width=450>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCag6lk2mSwU",
        "colab_type": "code",
        "outputId": "7f38f54e-14c9-420f-87f5-f984ca1a5b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Max pooling\n",
        "kernel_size = 2\n",
        "pool1 = nn.MaxPool1d(kernel_size=kernel_size, stride=2, padding=0)\n",
        "pool_output = pool1(conv_output)\n",
        "print(\"Size: {}\".format(pool_output.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([64, 5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_e4QRFwvTt8",
        "colab_type": "text"
      },
      "source": [
        "$\\frac{W-F}{S} + 1 = \\frac{7-2}{2} + 1 =  \\text{floor }(2.5) + 1 = 3$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9rL1EWIfi-y",
        "colab_type": "text"
      },
      "source": [
        "# CNNs on text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWtHDOJgHZvk",
        "colab_type": "text"
      },
      "source": [
        "We're going use convolutional neural networks on text data which typically involves convolving on the character level representation of the text to capture meaningful n-grams. \n",
        "\n",
        "You can easily use this set up for [time series](https://arxiv.org/abs/1807.10707) data or [combine it](https://arxiv.org/abs/1808.04928) with other networks. For text data, we will create filters of varying kernel sizes (1,2), (1,3), and (1,4) which act as feature selectors of varying n-gram sizes. The outputs are concated and fed into a fully-connected layer for class predictions. In our example, we will be applying 1D convolutions on letter in a word. In the [embeddings notebook](https://colab.research.google.com/github/GokuMohandas/practicalAI/blob/master/notebooks/12_Embeddings.ipynb), we will apply 1D convolutions on words in a sentence.\n",
        "\n",
        "**Word embeddings**: capture the temporal correlations among\n",
        "adjacent tokens so that similar words have similar representations. Ex. \"New Jersey\" is close to \"NJ\" is close to \"Garden State\", etc.\n",
        "\n",
        "**Char embeddings**: create representations that map words at a character level. Ex. \"toy\" and \"toys\" will be close to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVBZxbaAtS9u",
        "colab_type": "text"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8QSdEcDtXUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "import collections\n",
        "import copy\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VADCXjMwtXYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Numpy and PyTorch seeds\n",
        "def set_seeds(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "# Creating directories\n",
        "def create_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpiCYECstXbT",
        "colab_type": "code",
        "outputId": "639bc5e4-4dd5-436c-8efd-e761ac88218b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Arguments\n",
        "args = Namespace(\n",
        "    seed=1234,\n",
        "    cuda=False,\n",
        "    shuffle=True,\n",
        "    data_file=\"names.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"names\",\n",
        "    train_size=0.7,\n",
        "    val_size=0.15,\n",
        "    test_size=0.15,\n",
        "    num_epochs=20,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=64,\n",
        "    num_filters=100,\n",
        "    dropout_p=0.1,\n",
        ")\n",
        "\n",
        "# Set seeds\n",
        "set_seeds(seed=args.seed, cuda=args.cuda)\n",
        "\n",
        "# Create save dir\n",
        "create_dirs(args.save_dir)\n",
        "\n",
        "# Expand filepaths\n",
        "args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
        "args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptb4hJ4Bw8YU",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNxZQUqfmS0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBdQpUTQtMgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload data from GitHub to notebook's local drive\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/surnames.csv\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "with open(args.data_file, 'wb') as fp:\n",
        "    fp.write(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PYCeGrStMj7",
        "colab_type": "code",
        "outputId": "199ab5d3-b6fa-4163-9dcb-5ba5bd315751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Raw data\n",
        "df = pd.read_csv(args.data_file, header=0)\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surname</th>\n",
              "      <th>nationality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Woodford</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coté</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kore</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Koury</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lebzak</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    surname nationality\n",
              "0  Woodford     English\n",
              "1      Coté      French\n",
              "2      Kore     English\n",
              "3     Koury      Arabic\n",
              "4    Lebzak     Russian"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbfVM-YatMnD",
        "colab_type": "code",
        "outputId": "1617acd0-4ac4-45b5-c0c3-c5b43a5914e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "# Split by nationality\n",
        "by_nationality = collections.defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    by_nationality[row.nationality].append(row.to_dict())\n",
        "for nationality in by_nationality:\n",
        "    print (\"{0}: {1}\".format(nationality, len(by_nationality[nationality])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: 2972\n",
            "French: 229\n",
            "Arabic: 1603\n",
            "Russian: 2373\n",
            "Japanese: 775\n",
            "Chinese: 220\n",
            "Italian: 600\n",
            "Czech: 414\n",
            "Irish: 183\n",
            "German: 576\n",
            "Greek: 156\n",
            "Spanish: 258\n",
            "Polish: 120\n",
            "Dutch: 236\n",
            "Vietnamese: 58\n",
            "Korean: 77\n",
            "Portuguese: 55\n",
            "Scottish: 75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdGOoKFjtMpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create split data\n",
        "final_list = []\n",
        "for _, item_list in sorted(by_nationality.items()):\n",
        "    if args.shuffle:\n",
        "        np.random.shuffle(item_list)\n",
        "    n = len(item_list)\n",
        "    n_train = int(args.train_size*n)\n",
        "    n_val = int(args.val_size*n)\n",
        "    n_test = int(args.test_size*n)\n",
        "\n",
        "  # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "    for item in item_list[n_train+n_val:]:\n",
        "        item['split'] = 'test'  \n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyDwlzzKtMsz",
        "colab_type": "code",
        "outputId": "9b1c0f5c-49b1-481e-f472-66e3842b8ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# df with split datasets\n",
        "split_df = pd.DataFrame(final_list)\n",
        "split_df[\"split\"].value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    7680\n",
              "test     1660\n",
              "val      1640\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17aHMQOwtMvh",
        "colab_type": "code",
        "outputId": "ad07eac4-59b7-46c8-91ac-875b29ded0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "    \n",
        "split_df.surname = split_df.surname.apply(preprocess_text)\n",
        "split_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nationality</th>\n",
              "      <th>split</th>\n",
              "      <th>surname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>bishara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>nahas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>ghanem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>tannous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>mikhail</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  nationality  split  surname\n",
              "0      Arabic  train  bishara\n",
              "1      Arabic  train    nahas\n",
              "2      Arabic  train   ghanem\n",
              "3      Arabic  train  tannous\n",
              "4      Arabic  train  mikhail"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nZBgfQTuAA8",
        "colab_type": "text"
      },
      "source": [
        "# Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeRVQlRZuBgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "\n",
        "        # Token to index\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self.token_to_idx = token_to_idx\n",
        "\n",
        "        # Index to token\n",
        "        self.idx_to_token = {idx: token \\\n",
        "                             for token, idx in self.token_to_idx.items()}\n",
        "        \n",
        "        # Add unknown token\n",
        "        self.add_unk = add_unk\n",
        "        self.unk_token = unk_token\n",
        "        if self.add_unk:\n",
        "            self.unk_index = self.add_token(self.unk_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'token_to_idx': self.token_to_idx,\n",
        "                'add_unk': self.add_unk, 'unk_token': self.unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token in self.token_to_idx:\n",
        "            index = self.token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self.token_to_idx)\n",
        "            self.token_to_idx[token] = index\n",
        "            self.idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def add_tokens(self, tokens):\n",
        "        return [self.add_token[token] for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        if self.add_unk:\n",
        "            index = self.token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            index =  self.token_to_idx[token]\n",
        "        return index\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH8LMH9wuBi9",
        "colab_type": "code",
        "outputId": "98c18ff5-31a9-4bc8-b80b-e934ad234103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Vocabulary instance\n",
        "nationality_vocab = Vocabulary(add_unk=False)\n",
        "for index, row in df.iterrows():\n",
        "    nationality_vocab.add_token(row.nationality)\n",
        "print (nationality_vocab) # __str__\n",
        "index = nationality_vocab.lookup_token(\"English\")\n",
        "print (index)\n",
        "print (nationality_vocab.lookup_index(index))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary(size=18)>\n",
            "0\n",
            "English\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57a1lzHPuHHm",
        "colab_type": "text"
      },
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwS5BEV-uBlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SurnameVectorizer(object):\n",
        "    def __init__(self, surname_vocab, nationality_vocab):\n",
        "        self.surname_vocab = surname_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "\n",
        "    def vectorize(self, surname):\n",
        "        one_hot_matrix_size = (len(surname), len(self.surname_vocab))\n",
        "        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)\n",
        "                               \n",
        "        for position_index, character in enumerate(surname):\n",
        "            character_index = self.surname_vocab.lookup_token(character)\n",
        "            one_hot_matrix[position_index][character_index] = 1\n",
        "        \n",
        "        return one_hot_matrix\n",
        "    \n",
        "    def unvectorize(self, one_hot_matrix):\n",
        "        len_name = len(one_hot_matrix)\n",
        "        indices = np.zeros(len_name)\n",
        "        for i in range(len_name):\n",
        "            indices[i] = np.where(one_hot_matrix[i]==1)[0][0]\n",
        "        surname = [self.surname_vocab.lookup_index(index) for index in indices]\n",
        "        return surname\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df):\n",
        "        surname_vocab = Vocabulary(add_unk=True)\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\n",
        "\n",
        "        # Create vocabularies\n",
        "        for index, row in df.iterrows():\n",
        "            for letter in row.surname: # char-level tokenization\n",
        "                surname_vocab.add_token(letter)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "        return cls(surname_vocab, nationality_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\n",
        "        nationality_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "        return cls(surname_vocab, nationality_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq7RoFAXuBo9",
        "colab_type": "code",
        "outputId": "24caeac9-4650-4324-cee7-6413d3d803b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "# Vectorizer instance\n",
        "vectorizer = SurnameVectorizer.from_dataframe(split_df)\n",
        "print (vectorizer.surname_vocab)\n",
        "print (vectorizer.nationality_vocab)\n",
        "vectorized_surname = vectorizer.vectorize(preprocess_text(\"goku\"))\n",
        "print (np.shape(vectorized_surname))\n",
        "print (vectorized_surname)\n",
        "print (vectorizer.unvectorize(vectorized_surname))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary(size=28)>\n",
            "<Vocabulary(size=18)>\n",
            "(4, 28)\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]]\n",
            "['g', 'o', 'k', 'u']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwQ8MNp5ZfeG",
        "colab_type": "text"
      },
      "source": [
        "**Note**: Unlike the bagged ont-hot encoding method in the MLP notebook, we are able to preserve the semantic structure of the surnames. We are able to use one-hot encoding here because we are using characters but when we process text with large vocabularies, this method simply can't scale. We'll explore embedding based methods in subsequent notebooks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnf7gXgKuOgp",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYqzM53fuBrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjolk855uPrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, df, vectorizer):\n",
        "        self.df = df\n",
        "        self.vectorizer = vectorizer\n",
        "\n",
        "        # Data splits\n",
        "        self.train_df = self.df[self.df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "        self.val_df = self.df[self.df.split=='val']\n",
        "        self.val_size = len(self.val_df)\n",
        "        self.test_df = self.df[self.df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "        self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                            'val': (self.val_df, self.val_size),\n",
        "                            'test': (self.test_df, self.test_size)}\n",
        "        self.set_split('train')\n",
        "\n",
        "        # Class weights (for imbalances)\n",
        "        class_counts = df.nationality.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self.vectorizer.nationality_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, df):\n",
        "        train_df = df[df.split=='train']\n",
        "        return cls(df, SurnameVectorizer.from_dataframe(train_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, df, vectorizer_filepath):\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(df, vectorizer)\n",
        "\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self.vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self.target_split = split\n",
        "        self.target_df, self.target_size = self.lookup_dict[split]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Dataset(split={0}, size={1})\".format(\n",
        "            self.target_split, self.target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.target_df.iloc[index]\n",
        "        surname_vector = self.vectorizer.vectorize(row.surname)\n",
        "        nationality_index = self.vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "        return {'surname': surname_vector, 'nationality': nationality_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    def generate_batches(self, batch_size, collate_fn, shuffle=True, \n",
        "                         drop_last=True, device=\"cpu\"):\n",
        "        dataloader = DataLoader(dataset=self, batch_size=batch_size,\n",
        "                                collate_fn=collate_fn, shuffle=shuffle, \n",
        "                                drop_last=drop_last)\n",
        "        for data_dict in dataloader:\n",
        "            out_data_dict = {}\n",
        "            for name, tensor in data_dict.items():\n",
        "                out_data_dict[name] = data_dict[name].to(device)\n",
        "            yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvy-CJVSuPuS",
        "colab_type": "code",
        "outputId": "6b657b92-ae3b-458d-94c9-7ea6be5b6a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Dataset instance\n",
        "dataset = SurnameDataset.load_dataset_and_make_vectorizer(split_df)\n",
        "print (dataset) # __str__\n",
        "print (np.shape(dataset[5]['surname'])) # __getitem__\n",
        "print (dataset.class_weights)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Dataset(split=train, size=7680)\n",
            "(6, 28)\n",
            "tensor([0.0006, 0.0045, 0.0024, 0.0042, 0.0003, 0.0044, 0.0017, 0.0064, 0.0055,\n",
            "        0.0017, 0.0013, 0.0130, 0.0083, 0.0182, 0.0004, 0.0133, 0.0039, 0.0172])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY0CqM2Rd3Im",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWGpAzKPd32f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Q0_nkjd30L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SurnameModel(nn.Module):\n",
        "    def __init__(self, num_input_channels, num_output_channels, num_classes, dropout_p):\n",
        "        super(SurnameModel, self).__init__()\n",
        "        \n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(num_input_channels, num_output_channels, \n",
        "                                             kernel_size=f) for f in [2,3,4]])\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "       \n",
        "        # FC weights\n",
        "        self.fc1 = nn.Linear(num_output_channels*3, num_classes)\n",
        "\n",
        "    def forward(self, x, channel_first=False, apply_softmax=False):\n",
        "        \n",
        "        # Rearrange input so num_input_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x = x.transpose(1, 2)\n",
        "            \n",
        "        # Conv outputs\n",
        "        z = [conv(x) for conv in self.conv]\n",
        "        z = [F.max_pool1d(zz, zz.size(2)).squeeze(2) for zz in z]\n",
        "        z = [F.relu(zz) for zz in z]\n",
        "        \n",
        "        # Concat conv outputs\n",
        "        z = torch.cat(z, 1)\n",
        "        z = self.dropout(z)\n",
        "\n",
        "        # FC layer\n",
        "        y_pred = self.fc1(z)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XlJwSKQkL_C",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh_1heUNSUYN",
        "colab_type": "text"
      },
      "source": [
        "**Padding:** the inputs in a particular batch must all have the same shape. Our vectorizer converts the tokens into a vectorizer form but in a particular batch, we can have inputs of various sizes. The solution is to determine the longest input in a particular batch and pad all the other inputs to match that length. Usually, the smaller inputs in the batch are padded with zero vectors. \n",
        "\n",
        "We do this using the pad_seq function in the Trainer class which is invoked by the collate_fn which is passed to generate_batches function in the Dataset class. Essentially, the batch generater generates samples into a batch and we use the collate_fn to determine the largest input and pad all the other inputs in the batch to get a uniform input shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLLmIuKRkNYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV-Dc_5ykNgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, dataset, model, model_state_file, save_dir, device, shuffle, \n",
        "               num_epochs, batch_size, learning_rate, early_stopping_criteria):\n",
        "        self.dataset = dataset\n",
        "        self.class_weights = dataset.class_weights.to(device)\n",
        "        self.model = model.to(device)\n",
        "        self.save_dir = save_dir\n",
        "        self.device = device\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
        "        self.train_state = {\n",
        "            'done_training': False,\n",
        "            'stop_early': False, \n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'early_stopping_criteria': early_stopping_criteria,\n",
        "            'learning_rate': learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': model_state_file}\n",
        "    \n",
        "    def update_train_state(self):\n",
        "\n",
        "        # Verbose\n",
        "        print (\"[EPOCH]: {0} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
        "          self.train_state['epoch_index'], self.train_state['learning_rate'], \n",
        "            self.train_state['train_loss'][-1], self.train_state['train_acc'][-1], \n",
        "            self.train_state['val_loss'][-1], self.train_state['val_acc'][-1]))\n",
        "\n",
        "        # Save one model at least\n",
        "        if self.train_state['epoch_index'] == 0:\n",
        "            torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "            self.train_state['stop_early'] = False\n",
        "\n",
        "        # Save model if performance improved\n",
        "        elif self.train_state['epoch_index'] >= 1:\n",
        "            loss_tm1, loss_t = self.train_state['val_loss'][-2:]\n",
        "\n",
        "            # If loss worsened\n",
        "            if loss_t >= self.train_state['early_stopping_best_val']:\n",
        "                # Update step\n",
        "                self.train_state['early_stopping_step'] += 1\n",
        "\n",
        "            # Loss decreased\n",
        "            else:\n",
        "                # Save the best model\n",
        "                if loss_t < self.train_state['early_stopping_best_val']:\n",
        "                    torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "\n",
        "                # Reset early stopping step\n",
        "                self.train_state['early_stopping_step'] = 0\n",
        "\n",
        "            # Stop early ?\n",
        "            self.train_state['stop_early'] = self.train_state['early_stopping_step'] \\\n",
        "              >= self.train_state['early_stopping_criteria']\n",
        "        return self.train_state\n",
        "  \n",
        "    def compute_accuracy(self, y_pred, y_target):\n",
        "        _, y_pred_indices = y_pred.max(dim=1)\n",
        "        n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "        return n_correct / len(y_pred_indices) * 100\n",
        "    \n",
        "    def pad_seq(self, seq, length):\n",
        "        vector = np.zeros((length, len(self.dataset.vectorizer.surname_vocab)),\n",
        "                          dtype=np.int64)\n",
        "        for i in range(len(seq)):\n",
        "            vector[i] = seq[i]\n",
        "        return vector\n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "        \n",
        "        # Make a deep copy\n",
        "        batch_copy = copy.deepcopy(batch)\n",
        "        processed_batch = {\"surname\": [], \"nationality\": []}\n",
        "        \n",
        "        # Get max sequence length\n",
        "        max_seq_len = max([len(sample[\"surname\"]) for sample in batch_copy])\n",
        "        \n",
        "        # Pad\n",
        "        for i, sample in enumerate(batch_copy):\n",
        "            seq = sample[\"surname\"]\n",
        "            nationality = sample[\"nationality\"]\n",
        "            padded_seq = self.pad_seq(seq, max_seq_len)\n",
        "            processed_batch[\"surname\"].append(padded_seq)\n",
        "            processed_batch[\"nationality\"].append(nationality)\n",
        "            \n",
        "        # Convert to appropriate tensor types\n",
        "        processed_batch[\"surname\"] = torch.FloatTensor(\n",
        "            processed_batch[\"surname\"]) # need float for conv operations\n",
        "        processed_batch[\"nationality\"] = torch.LongTensor(\n",
        "            processed_batch[\"nationality\"])\n",
        "        \n",
        "        return processed_batch    \n",
        "  \n",
        "    def run_train_loop(self):\n",
        "        for epoch_index in range(self.num_epochs):\n",
        "            self.train_state['epoch_index'] = epoch_index\n",
        "      \n",
        "            # Iterate over train dataset\n",
        "\n",
        "            # initialize batch generator, set loss and acc to 0, set train mode on\n",
        "            self.dataset.set_split('train')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, collate_fn=self.collate_fn,\n",
        "                shuffle=self.shuffle, device=self.device)\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            self.model.train()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "                # zero the gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # compute the output\n",
        "                y_pred = self.model(batch_dict['surname'])\n",
        "\n",
        "                # compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "                loss_t = loss.item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # compute gradients using loss\n",
        "                loss.backward()\n",
        "\n",
        "                # use optimizer to take a gradient step\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['train_loss'].append(running_loss)\n",
        "            self.train_state['train_acc'].append(running_acc)\n",
        "\n",
        "            # Iterate over val dataset\n",
        "\n",
        "            # initialize batch generator, set loss and acc to 0; set eval mode on\n",
        "            self.dataset.set_split('val')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, collate_fn=self.collate_fn, \n",
        "                shuffle=self.shuffle, device=self.device)\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "                # compute the output\n",
        "                y_pred =  self.model(batch_dict['surname'])\n",
        "\n",
        "                # compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "                loss_t = loss.to(\"cpu\").item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['val_loss'].append(running_loss)\n",
        "            self.train_state['val_acc'].append(running_acc)\n",
        "\n",
        "            self.train_state = self.update_train_state()\n",
        "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
        "            if self.train_state['stop_early']:\n",
        "                break\n",
        "          \n",
        "    def run_test_loop(self):\n",
        "        # initialize batch generator, set loss and acc to 0; set eval mode on\n",
        "        self.dataset.set_split('test')\n",
        "        batch_generator = self.dataset.generate_batches(\n",
        "            batch_size=self.batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=self.shuffle, device=self.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        self.model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred =  self.model(batch_dict['surname'])\n",
        "\n",
        "            # compute the loss\n",
        "            loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "        self.train_state['test_loss'] = running_loss\n",
        "        self.train_state['test_acc'] = running_acc\n",
        "    \n",
        "    def plot_performance(self):\n",
        "        # Figure size\n",
        "        plt.figure(figsize=(15,5))\n",
        "\n",
        "        # Plot Loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(trainer.train_state[\"train_loss\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_loss\"], label=\"val\")\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "        # Plot Accuracy\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(trainer.train_state[\"train_acc\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_acc\"], label=\"val\")\n",
        "        plt.legend(loc='lower right')\n",
        "\n",
        "        # Save figure\n",
        "        plt.savefig(os.path.join(self.save_dir, \"performance.png\"))\n",
        "\n",
        "        # Show plots\n",
        "        plt.show()\n",
        "    \n",
        "    def save_train_state(self):\n",
        "        self.train_state[\"done_training\"] = True\n",
        "        with open(os.path.join(self.save_dir, \"train_state.json\"), \"w\") as fp:\n",
        "            json.dump(self.train_state, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkeOQRwckNd1",
        "colab_type": "code",
        "outputId": "75d9759c-21ad-4ed2-c2d9-21edfc8b27db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "# Initialization\n",
        "dataset = SurnameDataset.load_dataset_and_make_vectorizer(split_df)\n",
        "dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = SurnameModel(num_input_channels=len(vectorizer.surname_vocab),\n",
        "                     num_output_channels=args.num_filters,\n",
        "                     num_classes=len(vectorizer.nationality_vocab),\n",
        "                     dropout_p=args.dropout_p)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_modules of SurnameModel(\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(28, 100, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d(28, 100, kernel_size=(3,), stride=(1,))\n",
            "    (2): Conv1d(28, 100, kernel_size=(4,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1)\n",
            "  (fc1): Linear(in_features=300, out_features=18, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JJdOO4ZkNb3",
        "colab_type": "code",
        "outputId": "89790033-0e1e-4313-a904-7432f00ebbe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# Train\n",
        "trainer = Trainer(dataset=dataset, model=model, \n",
        "                  model_state_file=args.model_state_file, \n",
        "                  save_dir=args.save_dir, device=args.device,\n",
        "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
        "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
        "                  early_stopping_criteria=args.early_stopping_criteria)\n",
        "trainer.run_train_loop()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[EPOCH]: 0 | [LR]: 0.001 | [TRAIN LOSS]: 2.82 | [TRAIN ACC]: 20.2% | [VAL LOSS]: 2.71 | [VAL ACC]: 37.1%\n",
            "[EPOCH]: 1 | [LR]: 0.001 | [TRAIN LOSS]: 2.54 | [TRAIN ACC]: 43.9% | [VAL LOSS]: 2.40 | [VAL ACC]: 49.8%\n",
            "[EPOCH]: 2 | [LR]: 0.001 | [TRAIN LOSS]: 2.18 | [TRAIN ACC]: 48.7% | [VAL LOSS]: 2.12 | [VAL ACC]: 48.2%\n",
            "[EPOCH]: 3 | [LR]: 0.001 | [TRAIN LOSS]: 1.88 | [TRAIN ACC]: 51.1% | [VAL LOSS]: 1.90 | [VAL ACC]: 50.6%\n",
            "[EPOCH]: 4 | [LR]: 0.001 | [TRAIN LOSS]: 1.67 | [TRAIN ACC]: 54.8% | [VAL LOSS]: 1.74 | [VAL ACC]: 50.6%\n",
            "[EPOCH]: 5 | [LR]: 0.001 | [TRAIN LOSS]: 1.52 | [TRAIN ACC]: 57.4% | [VAL LOSS]: 1.65 | [VAL ACC]: 55.8%\n",
            "[EPOCH]: 6 | [LR]: 0.001 | [TRAIN LOSS]: 1.37 | [TRAIN ACC]: 60.0% | [VAL LOSS]: 1.60 | [VAL ACC]: 60.4%\n",
            "[EPOCH]: 7 | [LR]: 0.001 | [TRAIN LOSS]: 1.28 | [TRAIN ACC]: 62.2% | [VAL LOSS]: 1.53 | [VAL ACC]: 59.8%\n",
            "[EPOCH]: 8 | [LR]: 0.001 | [TRAIN LOSS]: 1.20 | [TRAIN ACC]: 62.9% | [VAL LOSS]: 1.49 | [VAL ACC]: 58.5%\n",
            "[EPOCH]: 9 | [LR]: 0.001 | [TRAIN LOSS]: 1.12 | [TRAIN ACC]: 64.4% | [VAL LOSS]: 1.43 | [VAL ACC]: 61.9%\n",
            "[EPOCH]: 10 | [LR]: 0.001 | [TRAIN LOSS]: 1.05 | [TRAIN ACC]: 65.8% | [VAL LOSS]: 1.40 | [VAL ACC]: 62.7%\n",
            "[EPOCH]: 11 | [LR]: 0.001 | [TRAIN LOSS]: 1.00 | [TRAIN ACC]: 66.3% | [VAL LOSS]: 1.38 | [VAL ACC]: 63.3%\n",
            "[EPOCH]: 12 | [LR]: 0.001 | [TRAIN LOSS]: 0.95 | [TRAIN ACC]: 67.1% | [VAL LOSS]: 1.34 | [VAL ACC]: 64.8%\n",
            "[EPOCH]: 13 | [LR]: 0.001 | [TRAIN LOSS]: 0.90 | [TRAIN ACC]: 69.1% | [VAL LOSS]: 1.35 | [VAL ACC]: 63.9%\n",
            "[EPOCH]: 14 | [LR]: 0.001 | [TRAIN LOSS]: 0.86 | [TRAIN ACC]: 69.0% | [VAL LOSS]: 1.31 | [VAL ACC]: 67.9%\n",
            "[EPOCH]: 15 | [LR]: 0.001 | [TRAIN LOSS]: 0.82 | [TRAIN ACC]: 70.8% | [VAL LOSS]: 1.32 | [VAL ACC]: 65.2%\n",
            "[EPOCH]: 16 | [LR]: 0.001 | [TRAIN LOSS]: 0.78 | [TRAIN ACC]: 71.1% | [VAL LOSS]: 1.31 | [VAL ACC]: 66.1%\n",
            "[EPOCH]: 17 | [LR]: 0.001 | [TRAIN LOSS]: 0.74 | [TRAIN ACC]: 72.1% | [VAL LOSS]: 1.28 | [VAL ACC]: 69.2%\n",
            "[EPOCH]: 18 | [LR]: 0.001 | [TRAIN LOSS]: 0.72 | [TRAIN ACC]: 72.6% | [VAL LOSS]: 1.30 | [VAL ACC]: 68.2%\n",
            "[EPOCH]: 19 | [LR]: 0.001 | [TRAIN LOSS]: 0.71 | [TRAIN ACC]: 72.7% | [VAL LOSS]: 1.30 | [VAL ACC]: 69.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QLZfEyznVpT",
        "colab_type": "code",
        "outputId": "16c6a67c-2359-4f78-e666-091eb102c78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# Plot performance\n",
        "trainer.plot_performance()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAE/CAYAAADVKysfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npE1ERERERCSI/T9wJRAHoGU+PQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWGzMSaBnYMb",
        "colab_type": "code",
        "outputId": "ebf9bac0-221f-4b35-e72d-8f8d3e20735b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Test performance\n",
        "trainer.run_test_loop()\n",
        "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
        "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.30\n",
            "Test Accuracy: 68.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5672VEginYnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save all results\n",
        "trainer.save_train_state()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN1g2vP3nad_",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myr8QQjKnZ7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Inference(object):\n",
        "    def __init__(self, model, vectorizer, device=\"cpu\"):\n",
        "        self.model = model.to(device)\n",
        "        self.vectorizer = vectorizer\n",
        "        self.device = device\n",
        "  \n",
        "    def predict_nationality(self, dataset):\n",
        "        # Batch generator\n",
        "        batch_generator = dataset.generate_batches(\n",
        "            batch_size=len(dataset), shuffle=False, device=self.device)\n",
        "        self.model.eval()\n",
        "        \n",
        "        # Predict\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred =  self.model(batch_dict['surname'], apply_softmax=True)\n",
        "\n",
        "            # Top k nationalities\n",
        "            y_prob, indices = torch.topk(y_pred, k=len(self.vectorizer.nationality_vocab))\n",
        "            probabilities = y_prob.detach().to('cpu').numpy()[0]\n",
        "            indices = indices.detach().to('cpu').numpy()[0]\n",
        "\n",
        "            results = []\n",
        "            for probability, index in zip(probabilities, indices):\n",
        "                nationality = self.vectorizer.nationality_vocab.lookup_index(index)\n",
        "                results.append({'nationality': nationality, 'probability': probability})\n",
        "\n",
        "        return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VVn_zxkRcbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load vectorizer\n",
        "with open(args.vectorizer_file) as fp:\n",
        "    vectorizer = SurnameVectorizer.from_serializable(json.load(fp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx46FK2YRchi",
        "colab_type": "code",
        "outputId": "58555ade-1bdf-4f3d-f244-c9eadffdd128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "# Load the model\n",
        "model = SurnameModel(num_input_channels=len(vectorizer.surname_vocab),\n",
        "                     num_output_channels=args.num_filters,\n",
        "                     num_classes=len(vectorizer.nationality_vocab),\n",
        "                     dropout_p=args.dropout_p)\n",
        "model.load_state_dict(torch.load(args.model_state_file))\n",
        "print (model.named_modules)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_modules of SurnameModel(\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(28, 100, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d(28, 100, kernel_size=(3,), stride=(1,))\n",
            "    (2): Conv1d(28, 100, kernel_size=(4,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1)\n",
            "  (fc1): Linear(in_features=300, out_features=18, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZE2Ov4xRcfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize\n",
        "inference = Inference(model=model, vectorizer=vectorizer, device=args.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpPDszLpRfww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceDataset(Dataset):\n",
        "    def __init__(self, df, vectorizer):\n",
        "        self.df = df\n",
        "        self.vectorizer = vectorizer\n",
        "        self.target_size = len(self.df)\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Dataset(size={1})>\".format(self.target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "        surname_vector = self.vectorizer.vectorize(row.surname)\n",
        "        return {'surname': surname_vector}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    def generate_batches(self, batch_size, shuffle=True, drop_last=False, device=\"cpu\"):\n",
        "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
        "                                shuffle=shuffle, drop_last=drop_last)\n",
        "        for data_dict in dataloader:\n",
        "            out_data_dict = {}\n",
        "            for name, tensor in data_dict.items():\n",
        "                out_data_dict[name] = data_dict[name].to(device)\n",
        "            yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDpg2LPKRf0c",
        "colab_type": "code",
        "outputId": "caa9e007-306e-456d-e755-119c30052971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Inference\n",
        "surname = input(\"Enter a surname to classify: \")\n",
        "infer_df = pd.DataFrame([surname], columns=['surname'])\n",
        "infer_df.surname = infer_df.surname.apply(preprocess_text)\n",
        "infer_dataset = InferenceDataset(infer_df, vectorizer)\n",
        "results = inference.predict_nationality(dataset=infer_dataset)\n",
        "results"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a surname to classify: tt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-53a1f9f0f9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minfer_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minfer_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInferenceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_nationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-3bd73267fee2>\u001b[0m in \u001b[0;36mpredict_nationality\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# compute the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'surname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_softmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Top k nationalities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-163dd26cca27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, channel_first, apply_softmax)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Conv outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-163dd26cca27>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Conv outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    194\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    195\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 196\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQSsKNRSxjRB",
        "colab_type": "text"
      },
      "source": [
        "# Batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3EamVazx2hx",
        "colab_type": "text"
      },
      "source": [
        "Even though we standardized our inputs to have zero mean and unit variance to aid with convergence, our inputs change during training as they go through the different layers and nonlinearities. This is known as internal covariate shirt and it slows down training and requires us to use smaller learning rates. The solution is [batch normalization](https://arxiv.org/abs/1502.03167) (batchnorm) which makes normalization a part of the model's architecture. This allows us to use much higher learning rates and get better performance, faster.\n",
        "\n",
        "$ BN = \\frac{a - \\mu_{x}}{\\sqrt{\\sigma^2_{x} + \\epsilon}}  * \\gamma + \\beta $\n",
        "\n",
        "where:\n",
        "* $a$ = activation | $\\in \\mathbb{R}^{NXH}$ ($N$ is the number of samples, $H$ is the hidden dim)\n",
        "* $ \\mu_{x}$ = mean of each hidden | $\\in \\mathbb{R}^{1XH}$\n",
        "* $\\sigma^2_{x}$ = variance of each hidden | $\\in \\mathbb{R}^{1XH}$\n",
        "* $epsilon$ = noise\n",
        "* $\\gamma$ = scale parameter (learned parameter)\n",
        "* $\\beta$ = shift parameter (learned parameter)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9koMITOdzfZB",
        "colab_type": "text"
      },
      "source": [
        "But what does it mean for our activations to have zero mean and unit variance before the nonlinearity operation. It doesn't mean that the entire activation matrix has this property but instead batchnorm is applied on the hidden (num_output_channels in our case) dimension. So each hidden's mean and variance is calculated using all samples across the batch. Also, batchnorm uses the calcualted mean and variance of the activations in the batch during training. However, during test, the sample size could be skewed so the model uses the saved population mean and variance from training. PyTorch's [BatchNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d) class takes care of all of this for us automatically.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/batchnorm.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsWdAKVEHvyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model with batch normalization\n",
        "class SurnameModel_BN(nn.Module):\n",
        "    def __init__(self, num_input_channels, num_output_channels, num_classes, dropout_p):\n",
        "        super(SurnameModel_BN, self).__init__()\n",
        "        \n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(num_input_channels, num_output_channels, \n",
        "                                             kernel_size=f) for f in [2,3,4]])\n",
        "        self.conv_bn = nn.ModuleList([nn.BatchNorm1d(num_output_channels) # define batchnorms\n",
        "                                      for i in range(3)])\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "       \n",
        "        # FC weights\n",
        "        self.fc1 = nn.Linear(num_output_channels*3, num_classes)\n",
        "\n",
        "    def forward(self, x, channel_first=False, apply_softmax=False):\n",
        "        \n",
        "        # Rearrange input so num_input_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x = x.transpose(1, 2)\n",
        "            \n",
        "        # Conv outputs\n",
        "        z = [F.relu(conv_bn(conv(x))) for conv, conv_bn in zip(self.conv, self.conv_bn)]\n",
        "        z = [F.max_pool1d(zz, zz.size(2)).squeeze(2) for zz in z]\n",
        "        \n",
        "        # Concat conv outputs\n",
        "        z = torch.cat(z, 1)\n",
        "        z = self.dropout(z)\n",
        "\n",
        "        # FC layer\n",
        "        y_pred = self.fc1(z)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_QcGx4vN3bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialization\n",
        "dataset = SurnameDataset.load_dataset_and_make_vectorizer(split_df)\n",
        "dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = SurnameModel_BN(num_input_channels=len(vectorizer.surname_vocab),\n",
        "                        num_output_channels=args.num_filters,\n",
        "                        num_classes=len(vectorizer.nationality_vocab),\n",
        "                        dropout_p=args.dropout_p)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXzxtiaxmXi",
        "colab_type": "text"
      },
      "source": [
        "You can train this model with batch normalization and you'll notice that the validation results improve by ~2-5%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERMGiPgAPssx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "trainer = Trainer(dataset=dataset, model=model, \n",
        "                  model_state_file=args.model_state_file, \n",
        "                  save_dir=args.save_dir, device=args.device,\n",
        "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
        "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
        "                  early_stopping_criteria=args.early_stopping_criteria)\n",
        "trainer.run_train_loop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiAW6AL0QAJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot performance\n",
        "trainer.plot_performance()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPQH0NVwQAO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test performance\n",
        "trainer.run_test_loop()\n",
        "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
        "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6WRq-O3d1ba",
        "colab_type": "text"
      },
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEcbaRswd1d0",
        "colab_type": "text"
      },
      "source": [
        "* image classification example\n",
        "* segmentation\n",
        "* deep CNN architectures\n",
        "* small 3X3 filters\n",
        "* details on padding and stride (control receptive field, make every pixel the center of the filter, etc.)\n",
        "* network-in-network (1x1 conv)\n",
        "* residual connections / residual block\n",
        "* interpretability (which n-grams fire)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXf4SJtL6mK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}