{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The objective of this session is to practice with basic tensor manipulations in pytorch, to understand the\n",
    "relation between a tensor and its underlying storage, and get a sense of the e\u000eciency of tensor-based\n",
    "computation compared to their equivalent python iterative implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, time\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple views of a storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the matrix\n",
    "![Task 1](task 1 matrix.png)\n",
    "\n",
    "with no python loop.\n",
    "\n",
    "**Hint**: Use several torch.narrow , and torch.fill ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Tensor(13, 13).fill_(1)\n",
    "\n",
    "m.narrow(0, 1, 1).fill_(2)\n",
    "m.narrow(1, 1, 1).fill_(2)\n",
    "m.narrow(0, 6, 1).fill_(2)\n",
    "m.narrow(1, 6, 1).fill_(2)\n",
    "m.narrow(0, 11, 1).fill_(2)\n",
    "m.narrow(1, 11, 1).fill_(2)\n",
    "\n",
    "m.narrow(0, 3, 2).narrow(1, 3, 2).fill_(3)\n",
    "m.narrow(0, 3, 2).narrow(1, 8, 2).fill_(3)\n",
    "m.narrow(0, 8, 2).narrow(1, 3, 2).fill_(3)\n",
    "m.narrow(0, 8, 2).narrow(1, 8, 2).fill_(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Tensor(13, 13).fill_(1)\n",
    "\n",
    "m[3:5,3:5] = 3\n",
    "m[8:10,3:5] = 3\n",
    "m[3:5,8:10] = 3\n",
    "m[8:10,8:10] = 3\n",
    "\n",
    "m[:,1::5] = 2\n",
    "m[1::5,:] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 3., 3., 1., 2., 1., 3., 3., 1., 2., 1.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using python loops, create a square matrix M (a 2d tensor) of dimension 20 X 20, filled with\n",
    "random Gaussian coeffcients, and compute the eigenvalues of M^-1 diag(1; : : : ; 20)M.\n",
    "\n",
    "**Hint**: Use torch.arange , torch.diag , torch.mm , torch.inverse , torch.normal and torch.eig ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 20\n",
    "m = torch.Tensor(size, size).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_m = m.inverse()\n",
    "diag_tensor = torch.arange(1,size + 1).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diag_tensor = diag_tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20.0000,  0.0000],\n",
       "         [19.0000,  0.0000],\n",
       "         [ 1.0000,  0.0000],\n",
       "         [18.0000,  0.0000],\n",
       "         [ 2.0000,  0.0000],\n",
       "         [17.0000,  0.0000],\n",
       "         [16.0000,  0.0000],\n",
       "         [ 3.0000,  0.0000],\n",
       "         [ 4.0000,  0.0000],\n",
       "         [ 5.0000,  0.0000],\n",
       "         [15.0000,  0.0000],\n",
       "         [14.0000,  0.0000],\n",
       "         [ 6.0000,  0.0000],\n",
       "         [13.0000,  0.0000],\n",
       "         [ 7.0000,  0.0000],\n",
       "         [ 8.0000,  0.0000],\n",
       "         [12.0000,  0.0000],\n",
       "         [11.0000,  0.0000],\n",
       "         [10.0000,  0.0000],\n",
       "         [ 9.0000,  0.0000]]), tensor([]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(inv_m, torch.mm(diag_tensor, m)).eig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flops per second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate two square matrices of dimension 5000 X 5000 filled with random Gaussian coeffcients,\n",
    "compute their product, measure the time it takes, and estimate how many \n",
    "oating point products\n",
    "have been executed per second (should be in the billions or tens of billions).\n",
    "\n",
    "**Hint**: Use torch.normal , torch.mm , and time.perf counter ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 5000\n",
    "first_ten = secon_ten = torch.Tensor(size, size).normal_()\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "torch.mm(first_ten, secon_ten)\n",
    "t1_stop = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.052806960913415045 min\n"
     ]
    }
   ],
   "source": [
    "print(\"Elapsed time: \" + str((t1_stop-t1_start)/60) + \" min\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional reading: \n",
    "\n",
    "https://habr.com/company/intel/blog/144388/\n",
    "\n",
    "https://en.wikipedia.org/wiki/FLOPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function mul row , using python loops, that gets a 2d tensor as argument, and returns a\n",
    "tensor of same size, equal to the one given as argument, with the first row kept unchanged, the second\n",
    "multiplied by two, the third by three, etc. For instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Task 2](task 2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mul_row(m):\n",
    "    for index, row in enumerate(m,1):\n",
    "        m[index-1,:] = index * m[index-1,:]\n",
    "        \n",
    "def mul_row_fast(m):\n",
    "    m_tmp = torch.arange(1,m.size()[0]+1).view(m.size()[0],1)\n",
    "    m_tmp = m_tmp.long()\n",
    "    m = m.long()\n",
    "    torch.mul(m_tmp,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = (Tensor (4 , 8).fill_ (2.0), Tensor (10000 , 400).fill_ (2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For torch.Size([4, 8])\n",
      " LOOP elapsed time: 7.116169066042252e-06 min\n",
      " PYTORCH elapsed time: 1.7585148555099295e-05 min\n",
      " ratio LOOPtime / PYTORCHtime: 0.40466926075405396\n",
      "\n",
      "For torch.Size([10000, 400])\n",
      " LOOP elapsed time: 0.0030554537738093283 min\n",
      " PYTORCH elapsed time: 0.0009453214780686873 min\n",
      " ratio LOOPtime / PYTORCHtime: 3.2321848648268183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tensor in m:\n",
    "    print(\"For \" + str(tensor.size()))\n",
    "    \n",
    "    t1_start = time.perf_counter()\n",
    "    mul_row(tensor)\n",
    "    t1_stop = time.perf_counter()\n",
    "    tloop = (t1_stop-t1_start)/60\n",
    "\n",
    "    t1_start = time.perf_counter()\n",
    "    mul_row_fast(tensor)\n",
    "    t1_stop = time.perf_counter()\n",
    "    ttorch = (t1_stop-t1_start)/60\n",
    "\n",
    "    print(\" LOOP elapsed time: \" + str(tloop) + \" min\" )\n",
    "    print(\" PYTORCH elapsed time: \" + str(ttorch) + \" min\" )\n",
    "    print(\" ratio LOOPtime / PYTORCHtime: \" + str(tloop/ttorch) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
