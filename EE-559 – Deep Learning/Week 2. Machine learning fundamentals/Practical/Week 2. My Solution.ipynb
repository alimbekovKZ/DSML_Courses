{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE-559: Practical Session 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this session is to continue practicing with tensors, deal with a real data-set, and get a\n",
    "feeling of how good/bad are the k-nearest neighbor rule and the PCA dimension reduction on MNIST\n",
    "and CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import dlc_practical_prologue as prologue\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that gets a training set and a test sample and returns the label of the training point\n",
    "the closest to the latter.\n",
    "\n",
    "More precisely, write:\n",
    "\n",
    "def nearest_classification(train_input, train_target, x):\n",
    "\n",
    "where\n",
    "1. train_input is a 2d float tensor of dimension n * d containing the training vectors,\n",
    "1. train_target is a 1d long tensor of dimension n containing the training labels,\n",
    "1. x is 1d float tensor of dimension d containing the test vector,\n",
    "\n",
    "and the returned value is the class of the train sample closest to x for the L^2 norm.\n",
    "\n",
    "**Hint**: The function should have no python loop, and may use in particular torch.mean , torch.view ,\n",
    "torch.pow , torch.sum , and torch.sort or torch.min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "train_input torch.Size([1000, 784]) train_target torch.Size([1000])\n",
      "test_input torch.Size([1000, 784]) test_target torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = prologue.load_data()\n",
    "\n",
    "print('train_input', train_input.size(), 'train_target', train_target.size())\n",
    "print('test_input', test_input.size(), 'test_target', test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tensor = test_input[0]\n",
    "test_label = test_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db826fcf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_tensor.numpy().reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_classification(train_input, train_target, x):\n",
    "    value, index = torch.min(torch.mean(torch.pow((x - train_input), 2), 1), 0)\n",
    "   \n",
    "    return train_target[index].data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val= nearest_classification(train_input, train_target, test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function\n",
    "\n",
    "def compute_nb_errors(train_input, train_target, test_input, test_target, mean = None, proj = None):\n",
    "\n",
    "where\n",
    "1. train_input is a 2d float tensor of dimension n × d containing the train vectors,\n",
    "1. train_target is a 1d long tensor of dimension n containing the train labels,\n",
    "1. test_input is a 2d float tensor of dimension m × d containing the test vectors,\n",
    "1. test_target is a 1d long tensor of dimension m containing the test labels,\n",
    "1. mean is either None or a 1d float tensor of dimension d,\n",
    "1. proj is either None or a 2d float tensor of dimension c × d ,\n",
    "\n",
    "that subtracts mean (if it is not None) from the vectors of both train_input and test_input, apply the operator proj (if it is notNone) to both, and returns the number of classification errors using the 1-nearest-neighbor rule on the resulting data.\n",
    "\n",
    "**Hint**: Use in particular torch.mm ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_nb_errors(train_input, train_target, test_input, test_target, mean = None, \n",
    "                      proj = None):\n",
    "    \n",
    "    if mean is not None:\n",
    "        train_input = train_input - mean\n",
    "        test_input = test_input - mean\n",
    "    if proj is not None:\n",
    "        train_input = train_input.mm(torch.transpose(proj, 0, 1))\n",
    "        test_input = test_input.mm(torch.transpose(proj, 0, 1))\n",
    "    \n",
    "    nb_errors = 0\n",
    "    \n",
    "    for i in range(test_input.shape[0]):\n",
    "        if test_target[i].tolist() != nearest_classification(train_input, \n",
    "                                                             train_target, test_input[i]):\n",
    "            nb_errors += 1\n",
    "    \n",
    "    print(nb_errors)\n",
    "    \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "errors = compute_nb_errors(train_input, train_target, test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function\n",
    "\n",
    "def PCA(x):\n",
    "\n",
    "where x is a 2d float tensor of dimension n × d , which returns a pair composed of the 1d\n",
    "mean vector of dimension d and the PCA basis, ranked in decreasing order of the eigen-\n",
    "values, as a 2d tensor of dimension d × d.\n",
    "\n",
    "**Hint**: The function should have no python loop, and use in particular torch.eig , and torch.sort. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(x):\n",
    "    mean = x.mean(0)\n",
    "    b = x - mean\n",
    "    Sigma = b.t().mm(b)\n",
    "    eigen_values, eigen_vectors = Sigma.eig(True)\n",
    "    right_order = eigen_values[:,0].abs().sort(0, True)[1]\n",
    "    eigen_vectors = eigen_vectors.t()[right_order]\n",
    "    \n",
    "    return mean, eigen_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that all this makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the 1-nearest neighbor rule on data projected either a 100d random subspace (i.e. using a basis generated with a normal) and using the PCA basis for\n",
    "different dimensions (e.g. 3, 10, 50, 100).\n",
    "\n",
    "Compare also the performance between MNIST and CIFAR. Does all this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "Baseline nb_errors 172 error 17.20%\n"
     ]
    }
   ],
   "source": [
    "nb_errors = compute_nb_errors(train_input, train_target, test_input, test_target)\n",
    "print('Baseline nb_errors {:d} error {:.02f}%'.format(nb_errors, 100 * nb_errors / test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basis = train_input.new(100, train_input.size(1)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0934, -1.0244,  0.6601,  ...,  0.3504, -0.4037,  2.5439],\n",
       "        [-0.5280,  0.6436,  0.2753,  ...,  0.1433,  0.9295,  0.0826],\n",
       "        [-0.3237, -0.5254, -1.5891,  ..., -0.8893,  0.3388,  0.6074],\n",
       "        ...,\n",
       "        [ 0.9291, -0.1619,  0.3813,  ...,  0.6565, -0.7872, -0.0464],\n",
       "        [-1.1122,  0.1138, -0.1410,  ...,  0.3476,  1.4485, -2.5771],\n",
       "        [-1.2628,  2.5255, -1.8213,  ..., -0.2675, -0.7211, -2.6470]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "Random 100d nb_errors 198 error 19.80%\n"
     ]
    }
   ],
   "source": [
    "nb_errors = compute_nb_errors(train_input, train_target, test_input, test_target, None, basis)\n",
    "print('Random {:d}d nb_errors {:d} error {:.02f}%'.format(basis.size(0), nb_errors, 100 * nb_errors / test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean, basis = PCA(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "PCA 100d nb_errors 164 error 16.40%\n",
      "155\n",
      "PCA 50d nb_errors 155 error 15.50%\n",
      "214\n",
      "PCA 10d nb_errors 214 error 21.40%\n",
      "597\n",
      "PCA 3d nb_errors 597 error 59.70%\n"
     ]
    }
   ],
   "source": [
    "for d in [ 100, 50, 10, 3 ]:\n",
    "        basis = basis.narrow(0, 0, d)\n",
    "        nb_errors = compute_nb_errors(train_input, train_target, test_input, test_target, mean, basis)\n",
    "        print('PCA {:d}d nb_errors {:d} error {:.02f}%'.format(d, nb_errors, 100 * nb_errors / test_input.size(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
