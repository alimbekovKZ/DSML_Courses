{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE-559: Practical Session 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this session is to implement a convolutional network and test the influence of the architecture on the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-organize the code to de\f",
    "ne and use a function\n",
    "\n",
    "train model(model, train input, train target, mini batch size)\n",
    "\n",
    "**Hint**: My version is 605 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        nb_hidden = 200\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(9 * 64, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 9 * 64)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    criterion = nn.MSELoss()\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(25):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "        print(e, sum_loss)\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write and test a function compute nb errors(model, input, target, mini batch size) To compute the number of prediction mistakes using a \\winner-take-all\" rule, that is the class with the largest output is the predicted one.\n",
    "\n",
    "Run the training and test ten times, record the test error rates.\n",
    "\n",
    "With 25 epochs for training, the test error should be around 10% with the small sets, and around 0:7% with the full ones.\n",
    "\n",
    "**Hint**: My version is 424 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.112744241952896\n",
      "1 3.7884375154972076\n",
      "2 3.293623298406601\n",
      "3 2.9757575690746307\n",
      "4 2.6923083811998367\n",
      "5 2.554612949490547\n",
      "6 2.191692367196083\n",
      "7 2.039821520447731\n",
      "8 1.8264740705490112\n",
      "9 1.7693022191524506\n",
      "10 1.7337832748889923\n",
      "11 1.524839848279953\n",
      "12 1.41568061709404\n",
      "13 1.3072502315044403\n",
      "14 1.2673509791493416\n",
      "15 1.180831916630268\n",
      "16 1.0918994843959808\n",
      "17 1.0624010860919952\n",
      "18 0.985806442797184\n",
      "19 0.9667170196771622\n",
      "20 0.9843000769615173\n",
      "21 0.8600574359297752\n",
      "22 0.8859782591462135\n",
      "23 0.8162537552416325\n",
      "24 0.7888985760509968\n",
      "test error Net 10.30% 103/1000\n",
      "0 5.15368264913559\n",
      "1 3.899659186601639\n",
      "2 3.484398901462555\n",
      "3 3.080592781305313\n",
      "4 2.7276910692453384\n",
      "5 2.556036412715912\n",
      "6 2.260008215904236\n",
      "7 2.1066131740808487\n",
      "8 1.9061606377363205\n",
      "9 1.5893488973379135\n",
      "10 1.7481589615345001\n",
      "11 1.566649541258812\n",
      "12 1.3454816117882729\n",
      "13 1.2616227343678474\n",
      "14 1.2872117012739182\n",
      "15 1.2269280031323433\n",
      "16 1.1856093853712082\n",
      "17 1.0022987723350525\n",
      "18 1.0402314513921738\n",
      "19 0.9310659766197205\n",
      "20 0.9529038369655609\n",
      "21 0.8984668105840683\n",
      "22 0.8387720361351967\n",
      "23 0.8603837341070175\n",
      "24 0.7806149646639824\n",
      "test error Net 10.80% 108/1000\n",
      "0 5.1188492476940155\n",
      "1 3.724440097808838\n",
      "2 3.2644189596176147\n",
      "3 2.8402261435985565\n",
      "4 2.632937178015709\n",
      "5 2.2947360277175903\n",
      "6 2.1035150438547134\n",
      "7 2.0711402148008347\n",
      "8 1.8871815651655197\n",
      "9 1.7261611074209213\n",
      "10 1.608419120311737\n",
      "11 1.4502099752426147\n",
      "12 1.2982159480452538\n",
      "13 1.266230285167694\n",
      "14 1.2135287821292877\n",
      "15 1.1865023747086525\n",
      "16 1.1034826636314392\n",
      "17 0.992757998406887\n",
      "18 1.017319768667221\n",
      "19 0.9747220799326897\n",
      "20 0.9130084663629532\n",
      "21 0.8403706923127174\n",
      "22 0.8216323480010033\n",
      "23 0.7551911398768425\n",
      "24 0.7445613145828247\n",
      "test error Net 9.10% 91/1000\n",
      "0 5.436435639858246\n",
      "1 4.0330711007118225\n",
      "2 3.3610242009162903\n",
      "3 3.0269017815589905\n",
      "4 2.6319284439086914\n",
      "5 2.364153206348419\n",
      "6 2.045560583472252\n",
      "7 1.9033859223127365\n",
      "8 1.683135911822319\n",
      "9 1.774775579571724\n",
      "10 1.5548436492681503\n",
      "11 1.3364577442407608\n",
      "12 1.38573257625103\n",
      "13 1.2859396412968636\n",
      "14 1.2323938757181168\n",
      "15 1.0497734174132347\n",
      "16 1.0618291944265366\n",
      "17 1.0136537700891495\n",
      "18 0.9306575655937195\n",
      "19 0.9480679556727409\n",
      "20 0.9723203852772713\n",
      "21 0.7941323965787888\n",
      "22 0.8070192933082581\n",
      "23 0.7955626174807549\n",
      "24 0.7916738763451576\n",
      "test error Net 11.80% 118/1000\n",
      "0 5.082888275384903\n",
      "1 3.852471202611923\n",
      "2 3.40842005610466\n",
      "3 3.0106576681137085\n",
      "4 2.92710117995739\n",
      "5 2.5410003811120987\n",
      "6 2.379149630665779\n",
      "7 2.15378800034523\n",
      "8 1.9843265414237976\n",
      "9 1.8482839912176132\n",
      "10 1.6350017040967941\n",
      "11 1.5852938741445541\n",
      "12 1.4029327407479286\n",
      "13 1.4224468022584915\n",
      "14 1.2801788970828056\n",
      "15 1.171655759215355\n",
      "16 1.185708187520504\n",
      "17 1.064056321978569\n",
      "18 1.0219205543398857\n",
      "19 0.9732667282223701\n",
      "20 0.9518451914191246\n",
      "21 0.8702620193362236\n",
      "22 0.8781041577458382\n",
      "23 0.8322962448000908\n",
      "24 0.765097551047802\n",
      "test error Net 9.00% 90/1000\n",
      "0 4.735131561756134\n",
      "1 3.9110785722732544\n",
      "2 3.530549496412277\n",
      "3 3.0895249247550964\n",
      "4 2.7527416944503784\n",
      "5 2.468291163444519\n",
      "6 2.1886792927980423\n",
      "7 2.262865200638771\n",
      "8 2.061009854078293\n",
      "9 1.7351677268743515\n",
      "10 1.711625024676323\n",
      "11 1.5124875754117966\n",
      "12 1.6044986248016357\n",
      "13 1.3693906515836716\n",
      "14 1.2838539332151413\n",
      "15 1.2575165033340454\n",
      "16 1.1094448640942574\n",
      "17 1.1342320442199707\n",
      "18 0.9633239880204201\n",
      "19 1.011068344116211\n",
      "20 0.8957034051418304\n",
      "21 0.9403620362281799\n",
      "22 0.9302226454019547\n",
      "23 0.822365365922451\n",
      "24 0.8263159543275833\n",
      "test error Net 11.50% 115/1000\n",
      "0 5.151097625494003\n",
      "1 3.8046056032180786\n",
      "2 3.5937485694885254\n",
      "3 2.910322278738022\n",
      "4 2.864091694355011\n",
      "5 2.3923082053661346\n",
      "6 2.319252237677574\n",
      "7 2.006980210542679\n",
      "8 1.8445848375558853\n",
      "9 1.6484186351299286\n",
      "10 1.494578868150711\n",
      "11 1.3561908602714539\n",
      "12 1.2735538557171822\n",
      "13 1.2848187237977982\n",
      "14 1.1468048840761185\n",
      "15 1.0552476420998573\n",
      "16 0.9425658956170082\n",
      "17 0.9562794417142868\n",
      "18 0.9415606185793877\n",
      "19 0.9180677980184555\n",
      "20 0.7934467643499374\n",
      "21 0.7813830263912678\n",
      "22 0.8104778751730919\n",
      "23 0.7153586409986019\n",
      "24 0.6869883723556995\n",
      "test error Net 8.70% 87/1000\n",
      "0 5.314215183258057\n",
      "1 3.8494093120098114\n",
      "2 3.4100795090198517\n",
      "3 3.0175070762634277\n",
      "4 2.7150488048791885\n",
      "5 2.6620577424764633\n",
      "6 2.354529470205307\n",
      "7 2.0411338806152344\n",
      "8 1.9023678004741669\n",
      "9 1.7073049694299698\n",
      "10 1.755111813545227\n",
      "11 1.578220248222351\n",
      "12 1.4241802543401718\n",
      "13 1.3759178519248962\n",
      "14 1.2778945937752724\n",
      "15 1.1841404736042023\n",
      "16 1.1561125218868256\n",
      "17 1.2170204520225525\n",
      "18 0.9677199497818947\n",
      "19 1.0199980065226555\n",
      "20 0.9599164873361588\n",
      "21 0.8958687707781792\n",
      "22 0.8368421494960785\n",
      "23 0.7839711159467697\n",
      "24 0.7643699645996094\n",
      "test error Net 9.90% 99/1000\n",
      "0 5.047738581895828\n",
      "1 3.7879641354084015\n",
      "2 3.3920859694480896\n",
      "3 3.019070476293564\n",
      "4 2.7118132561445236\n",
      "5 2.5990684926509857\n",
      "6 2.260972484946251\n",
      "7 2.124704986810684\n",
      "8 1.9147594273090363\n",
      "9 1.7734262943267822\n",
      "10 1.726860523223877\n",
      "11 1.5781465917825699\n",
      "12 1.4030039310455322\n",
      "13 1.393563598394394\n",
      "14 1.3147405683994293\n",
      "15 1.2396252378821373\n",
      "16 1.1760610342025757\n",
      "17 1.0551698878407478\n",
      "18 1.0664340555667877\n",
      "19 0.9437732771039009\n",
      "20 1.0105534568428993\n",
      "21 0.855385035276413\n",
      "22 0.9641894996166229\n",
      "23 0.8632423430681229\n",
      "24 0.7960612550377846\n",
      "test error Net 10.10% 101/1000\n",
      "0 4.78747883439064\n",
      "1 4.025645464658737\n",
      "2 3.5127072632312775\n",
      "3 2.9755409508943558\n",
      "4 2.7797774374485016\n",
      "5 2.59706549346447\n",
      "6 2.07672943174839\n",
      "7 2.2214492112398148\n",
      "8 2.0050048232078552\n",
      "9 1.7697352170944214\n",
      "10 1.7078762352466583\n",
      "11 1.6829127818346024\n",
      "12 1.502609208226204\n",
      "13 1.3626834079623222\n",
      "14 1.3772446289658546\n",
      "15 1.2278381660580635\n",
      "16 1.1662454530596733\n",
      "17 1.127514585852623\n",
      "18 1.113324150443077\n",
      "19 1.0640529468655586\n",
      "20 0.9993612095713615\n",
      "21 0.9099946320056915\n",
      "22 0.8891265764832497\n",
      "23 0.9322965368628502\n",
      "24 0.812479741871357\n",
      "test error Net 10.80% 108/1000\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    model = Net(200)\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of the number of hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the default network, the number of hidden units is 200.\n",
    "\n",
    "Modify the class constructor to take a parameter for that value, and run the training and compute the test error for 10, 50, 200, 500, and 1; 000 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.4363861083984375\n",
      "1 6.1824826300144196\n",
      "2 3.9167848229408264\n",
      "3 3.5962457060813904\n",
      "4 3.4197466373443604\n",
      "5 3.2805514335632324\n",
      "6 3.284749537706375\n",
      "7 3.1509396731853485\n",
      "8 3.029834121465683\n",
      "9 2.974440425634384\n",
      "10 2.9795414209365845\n",
      "11 2.8329491019248962\n",
      "12 2.7390788793563843\n",
      "13 2.660202071070671\n",
      "14 2.6478630900382996\n",
      "15 2.5123423784971237\n",
      "16 2.4170942455530167\n",
      "17 2.503698319196701\n",
      "18 2.433146670460701\n",
      "19 2.2901958376169205\n",
      "20 2.2602210640907288\n",
      "21 2.1708112955093384\n",
      "22 2.109923794865608\n",
      "23 2.2300566732883453\n",
      "24 2.0837640166282654\n",
      "test error Net nh=10 32.10%% 321/1000\n",
      "0 5.245264142751694\n",
      "1 3.884039491415024\n",
      "2 3.4805814623832703\n",
      "3 3.162073403596878\n",
      "4 2.8438534438610077\n",
      "5 2.673436015844345\n",
      "6 2.5241805762052536\n",
      "7 2.350790098309517\n",
      "8 2.1533184200525284\n",
      "9 1.8464730978012085\n",
      "10 1.8945660591125488\n",
      "11 1.6536803841590881\n",
      "12 1.6085084676742554\n",
      "13 1.5062538385391235\n",
      "14 1.4224064126610756\n",
      "15 1.5174818336963654\n",
      "16 1.3327990174293518\n",
      "17 1.2370204851031303\n",
      "18 1.2130172923207283\n",
      "19 1.1245168149471283\n",
      "20 1.0248086899518967\n",
      "21 0.962968498468399\n",
      "22 1.0341202840209007\n",
      "23 0.9294124320149422\n",
      "24 0.9054428264498711\n",
      "test error Net nh=50 12.30%% 123/1000\n",
      "0 5.103813886642456\n",
      "1 3.769577533006668\n",
      "2 3.4246610701084137\n",
      "3 3.0410152971744537\n",
      "4 2.704161360859871\n",
      "5 2.526951938867569\n",
      "6 2.303078979253769\n",
      "7 2.169843778014183\n",
      "8 1.9021745473146439\n",
      "9 1.876278579235077\n",
      "10 1.5721163004636765\n",
      "11 1.4975493103265762\n",
      "12 1.4917698055505753\n",
      "13 1.4044853821396828\n",
      "14 1.2476099207997322\n",
      "15 1.2017280533909798\n",
      "16 1.2325374335050583\n",
      "17 1.1023251488804817\n",
      "18 1.0331474244594574\n",
      "19 0.9626417309045792\n",
      "20 0.9492435082793236\n",
      "21 0.9214122071862221\n",
      "22 0.8464957475662231\n",
      "23 0.7996727451682091\n",
      "24 0.7956470921635628\n",
      "test error Net nh=200 11.60%% 116/1000\n",
      "0 5.255810260772705\n",
      "1 3.692017585039139\n",
      "2 3.143036901950836\n",
      "3 2.7140773981809616\n",
      "4 2.472971558570862\n",
      "5 2.256848618388176\n",
      "6 1.8684630244970322\n",
      "7 1.7600951194763184\n",
      "8 1.700812503695488\n",
      "9 1.4699826389551163\n",
      "10 1.3934859409928322\n",
      "11 1.2821794003248215\n",
      "12 1.2496191784739494\n",
      "13 1.1326523199677467\n",
      "14 1.1026639193296432\n",
      "15 0.9796438813209534\n",
      "16 1.0038793310523033\n",
      "17 0.8978264331817627\n",
      "18 0.8719455227255821\n",
      "19 0.7737306952476501\n",
      "20 0.7886213213205338\n",
      "21 0.8253126591444016\n",
      "22 0.7593999765813351\n",
      "23 0.7207301110029221\n",
      "24 0.6514446176588535\n",
      "test error Net nh=500 7.90%% 79/1000\n",
      "0 7.927204102277756\n",
      "1 4.4200073182582855\n",
      "2 3.8331957161426544\n",
      "3 3.3641363084316254\n",
      "4 2.9610798358917236\n",
      "5 2.566664144396782\n",
      "6 2.247730925679207\n",
      "7 2.181843101978302\n",
      "8 1.8556853979825974\n",
      "9 1.758981004357338\n",
      "10 1.594098299741745\n",
      "11 1.5297609567642212\n",
      "12 1.370951123535633\n",
      "13 1.2533042803406715\n",
      "14 1.222414955496788\n",
      "15 1.1706344485282898\n",
      "16 1.144149474799633\n",
      "17 0.9402496591210365\n",
      "18 1.0292914509773254\n",
      "19 0.8519866466522217\n",
      "20 0.8714767321944237\n",
      "21 0.8287883624434471\n",
      "22 0.8062592372298241\n",
      "23 0.862456738948822\n",
      "24 0.705607395619154\n",
      "test error Net nh=2500 10.10%% 101/1000\n"
     ]
    }
   ],
   "source": [
    "for nh in [ 10, 50, 200, 500, 2500 ]:\n",
    "    model = Net(nh)\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net nh={:d} {:0.2f}%% {:d}/{:d}'.format(nh,\n",
    "                                                              (100 * nb_test_errors) / test_input.size(0),\n",
    "                                                              nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a new class Net2 with three convolutional layers. Pick the structure you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.395033687353134\n",
      "1 4.229063153266907\n",
      "2 3.7480200231075287\n",
      "3 3.6354694962501526\n",
      "4 3.4385128915309906\n",
      "5 3.149120569229126\n",
      "6 2.8957360237836838\n",
      "7 2.6231420636177063\n",
      "8 2.449516549706459\n",
      "9 2.224852740764618\n",
      "10 2.016029581427574\n",
      "11 2.0044833421707153\n",
      "12 1.8064875900745392\n",
      "13 1.6726615279912949\n",
      "14 1.6341219395399094\n",
      "15 1.5118607133626938\n",
      "16 1.4863622039556503\n",
      "17 1.3760399147868156\n",
      "18 1.2655799984931946\n",
      "19 1.1814519092440605\n",
      "20 1.1100690364837646\n",
      "21 1.1050541400909424\n",
      "22 1.0946116000413895\n",
      "23 1.0108418762683868\n",
      "24 0.9369009137153625\n",
      "test error Net2 11.60%% 116/1000\n"
     ]
    }
   ],
   "source": [
    "model = Net2()\n",
    "train_model(model, train_input, train_target, mini_batch_size)\n",
    "nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "print('test error Net2 {:0.2f}%% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                   nb_test_errors, test_input.size(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
