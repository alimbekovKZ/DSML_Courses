{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagenet\n",
    "\n",
    "Largest image classification dataset at this point of time.\n",
    "\n",
    "Url: http://image-net.org/\n",
    "\n",
    "Our setup: classify from a set of 1000 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classes' names are stored here\n",
    "import pickle\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "print (classes[::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-trained model: inception\n",
    "Keras has a number of models for which you can use pre-trained weights. The interface is super-straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.1)\n",
    "s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.applications as zoo\n",
    "\n",
    "model = zoo.InceptionV3(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "%matplotlib inline\n",
    "\n",
    "img = imresize(plt.imread('sample_images/albatross.jpg'), (299,299))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img_preprocessed = zoo.inception_v3.preprocess_input(img[None].astype('float32'))\n",
    "\n",
    "probs = model.predict(img_preprocessed)\n",
    "\n",
    "labels = probs.ravel().argsort()[-1:-10:-1]\n",
    "print ('top-10 classes are:')\n",
    "for l in labels:\n",
    "    print ('%.4f\\t%s' % (probs.ravel()[l], classes[l].split(',')[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having fun with pre-trained nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget http://cdn.com.do/wp-content/uploads/2017/02/Donal-Trum-Derogar.jpeg -O img.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = imresize(plt.imread('img.jpg'), (299,299))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img_preprocessed = zoo.inception_v3.preprocess_input(img[None].astype('float32'))\n",
    "\n",
    "probs = model.predict(img_preprocessed)\n",
    "\n",
    "labels = probs.ravel().argsort()[-1:-10:-1]\n",
    "print ('top-10 classes are:')\n",
    "for l in labels:\n",
    "    print ('%.4f\\t%s' % (probs.ravel()[l], classes[l].split(',')[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you reuse layers\n",
    "\n",
    "Since model is just a sequence of layers, one can apply it as any other Keras model. Then you can build more layers on top of it, train them and maybe fine-tune \"body\" weights a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = keras.backend.Input('float32',[None,299,299,3])\n",
    "\n",
    "neck = zoo.InceptionV3(include_top=False, weights='imagenet')(img)\n",
    "\n",
    "hid = keras.layers.GlobalMaxPool2D()(neck)\n",
    "\n",
    "hid = keras.layers.Dense(512,activation='relu')(hid)\n",
    "\n",
    "out = keras.layers.Dense(10,activation='softmax')(hid)\n",
    "\n",
    "#<...> loss, training, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand-quest: Dogs Vs Cats\n",
    "* original competition\n",
    "* https://www.kaggle.com/c/dogs-vs-cats\n",
    "* 25k JPEG images of various size, 2 classes (guess what)\n",
    "\n",
    "### Your main objective\n",
    "* In this seminar your goal is to fine-tune a pre-trained model to distinguish between the two rivaling animals\n",
    "* The first step is to just reuse some network layer as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/d61lupw909hc785/dogs_vs_cats.train.zip?dl=1 -O data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for starters\n",
    "* Train sklearn model, evaluate validation accuracy (should be >80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract features from images\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "#this may be a tedious process. If so, store the results in some pickle and re-use them.\n",
    "for fname in tqdm(os.listdir('train/')):\n",
    "    y = fname.startswith(\"cat\")\n",
    "    img = imread(\"train/\"+fname)\n",
    "    img = imresize(img,(IMAGE_W,IMAGE_W))\n",
    "    img = zoo.inception_v3.preprocess_input(img[None].astype('float32'))\n",
    "    \n",
    "    features = <use network to process the image into features>\n",
    "    Y.append(y)\n",
    "    X.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.concatenate(X) #stack all [1xfeatures] matrices into one. \n",
    "assert X.ndim==2\n",
    "#WARNING! the concatenate works for [1xN] matrices. If you have other format, stack them yourself.\n",
    "\n",
    "#crop if we ended prematurely\n",
    "Y = Y[:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "<split data either here or use cross-validation>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load our dakka__\n",
    "![img](https://s-media-cache-ak0.pinimg.com/564x/80/a1/81/80a1817a928744a934a7d32e7c03b242.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main quest\n",
    "\n",
    "* Get the score improved!\n",
    "* You have to reach __at least 95%__ on the test set. More = better.\n",
    "\n",
    "No methods are illegal: ensembling, data augmentation, NN hacks. \n",
    "Just don't let test data slip into training.\n",
    "\n",
    "\n",
    "### Split the raw image data\n",
    "  * please do train/validation/test instead of just train/test\n",
    "  * reasonable but not optimal split is 20k/2.5k/2.5k or 15k/5k/5k\n",
    "\n",
    "### Choose which vgg layers are you going to use\n",
    "  * Anything but for prob is okay\n",
    "  * Do not forget that vgg16 uses dropout\n",
    "\n",
    "### Build a few layers on top of chosen \"neck\" layers.\n",
    "  * a good idea is to just stack more layers inside the same network\n",
    "  * alternative: stack on top of get_output\n",
    "\n",
    "### Train the newly added layers for some iterations\n",
    "  * you can selectively train some weights by setting var_list in the optimizer\n",
    "      * `opt = tf.train.AdamOptimizer(learning_rate=...)`\n",
    "      * `updates = opt.minimize(loss,var_list=variables_you_wanna_train)`\n",
    "  * it's cruicial to monitor the network performance at this and following steps\n",
    "\n",
    "### Fine-tune the network body\n",
    "  * probably a good idea to SAVE your new network weights now 'cuz it's easy to mess things up.\n",
    "  * Moreover, saving weights periodically is a no-nonsense idea\n",
    "  * even more cruicial to monitor validation performance\n",
    "  * main network body may need a separate, much lower learning rate\n",
    "      * you can create two update operations\n",
    "      * `opt1 = tf.train.AdamOptimizer(learning_rate=lr1)`\n",
    "      * `updates1 = opt1.minimize(loss,var_list=head_weights)`\n",
    "      * `opt2 = tf.train.AdamOptimizer(learning_rate=lr2)`\n",
    "      * `updates2 = opt2.minimize(loss,var_list=body_weights)`\n",
    "      * `s.run([updates1,updates2],{...})\n",
    " \n",
    "### Grading\n",
    "* 95% accuracy on test yields 10 points\n",
    "* -1 point per 5% less accuracy\n",
    "\n",
    "### Some ways to get bonus points\n",
    "* explore other networks from the model zoo\n",
    "* play with architecture\n",
    "* 96%/97%/98%/99%/99.5% test score (screen pls).\n",
    "* data augmentation, prediction-time data augmentation\n",
    "* use any more advanced fine-tuning technique you know/read anywhere\n",
    "* ml hacks that benefit the final score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<A whole lot of your code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
